# **DAGFed: A Dual-Perturbation and Adaptive Graph Framework for Secure and Robust Distributed Learning**

This repository contains the official implementation of **DAG_Fed**, a federated learning framework integrating **Dynamic Adaptive Gradient Clipping (DAGC)** and **Hierarchical Differential Privacy (HDP)** to improve both **privacy protection** and **model utility** under heterogeneous (non-IID) data distributions.

---

## **ğŸ“Œ Features**

* **Dynamic Client Selection & Adaptive Gradient Clipping** â€” Mitigates statistical heterogeneity by adaptively tuning gradient norms per client.
* **Hierarchical Differential Privacy (HDP)** â€” Multi-level noise injection for balanced **privacyâ€“utility trade-off**.
* **Modular Aggregator** â€” Supports **FedAvg**, **SCAFFOLD**, and custom aggregation strategies.
* **Flexible Data Partitioning** â€” IID and non-IID splits via Dirichlet sampling.
* **Reproducible Experiments** â€” Unified config file and logging system.

---

## **ğŸ“‚ Project Structure**

```
DAGC_HDP_Federated_Learning/
â”‚
â”œâ”€â”€ config.py                 # Global configuration: hyperparameters, DP budget, scenarios
â”œâ”€â”€ main.py                   # Main entry: training orchestration, global loop
â”‚
â”œâ”€â”€ clients/
â”‚   â”œâ”€â”€ client.py             # Client base class: data loading, local training, DAGC
â”‚   â”œâ”€â”€ dp_utils.py           # DP utilities: gradient clipping, noise injection
â”‚   â”œâ”€â”€ noise_scheduler.py    # Dynamic noise scheduling
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ aggregator.py         # Aggregators (FedAvg, SCAFFOLD, etc.)
â”‚   â”œâ”€â”€ privacy_accountant.py # DP budget tracking, RDP accounting
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model_cnn.py          # CNN model for vision datasets (CIFAR-10, MNIST)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data_loader.py        # Dataset loading & non-IID partitioning
â”‚   â”œâ”€â”€ datasets/             # Dataset storage
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ logger.py             # Logging utilities
â”‚   â”œâ”€â”€ metrics.py            # Accuracy, F1, MSE calculation
â”‚   â”œâ”€â”€ attack_test.py        # Privacy attack evaluation scripts
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ helper.py             # General utilities (seed, save/load, etc.)
â”‚   â”œâ”€â”€ plots.py              # Visualization of results
â”‚
â”œâ”€â”€ README.md                 # Project documentation
â””â”€â”€ requirements.txt          # Python dependencies
```

---

## **âš™ï¸ Installation**

### **1. Clone the repository**

```bash
git clone https://github.com/yourusername/DAGC_HDP_Federated_Learning.git
cd DAGC_HDP_Federated_Learning
```

### **2. Create a Python environment**

```bash
conda create -n dagc_hdp python=3.9
conda activate dagc_hdp
```

### **3. Install dependencies**

```bash
pip install -r requirements.txt
```

---

## **ğŸš€ Usage**

Run a CIFAR-10 experiment with 10 clients, 100 rounds, and a privacy budget of Îµ = 8.0:

```bash
python main.py --dataset cifar10 --rounds 100 --clients 10 --epsilon 8.0
```

**Key Arguments**:

* `--dataset` : `cifar10`, `cifar100`, `mnist`, `fashionmnist`
* `--rounds` : Number of global communication rounds
* `--clients` : Number of participating clients
* `--epsilon` : Privacy budget for DP
* Additional parameters can be set in `config.py`

---

